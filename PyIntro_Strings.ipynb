{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Python - Strings, Text Files and Regular Expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last update: 2017-04-26 14:11:07.592478\n"
     ]
    }
   ],
   "source": [
    "# Author: Alex Schmitt (schmitt@ifo.de)\n",
    "\n",
    "import datetime\n",
    "print('Last update: ' + str(datetime.datetime.today()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review: Strings\n",
    "\n",
    "We have already encountered strings in the first lecture. To recap, a string is a sequence of letters which is characterized by single or double quotation marks. In some sense, a string can be compared to a tuple: it is an ordered sequence, which is immutable - you cannot change, say, a single letter in a given string. We also saw that we can concatenate two strings using '+':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CESifo\n"
     ]
    }
   ],
   "source": [
    "S = 'ifo'\n",
    "# S[0] = 'I' ## this line would throw an error!\n",
    "S2 = 'CES' + S\n",
    "print(S2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, we will work with strings that we read from text files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handles and Reading Files\n",
    "\n",
    "\"Reading\" data from a text file consists of two steps. First, you *open a file handle* with the in-built **open** function. Then, you use a method (applicable on file handles) to extract the data. A frequently used method is **read()**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fname = 'email.txt'\n",
    "fh = open(fname)\n",
    "type(fh)\n",
    "text_all = fh.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**text_all** stores the contents of the text file as one large string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "The text consists of 1680 characters.\n"
     ]
    }
   ],
   "source": [
    "print(type(text_all))\n",
    "print('The text consists of {} characters.'.format(len(text_all)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes it is more convenient to have a list of strings instead, where *each element of the list represents a line* in the text (As so often, which one the better alternative is depends on what problem you wanna solve.). This is achieved by the **readlines** method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 35\n",
      "The text consists of 1680 characters.\n"
     ]
    }
   ],
   "source": [
    "fh = open(fname)\n",
    "text = fh.readlines()\n",
    "print(type(text), len(text))\n",
    "print('The text consists of {} characters.'.format( sum([len(x) for x in text]) ) ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## String Methods\n",
    "\n",
    "As other object types, strings have specific *methods* that only work on them. Here is a (incomplete) list of the most important methods for a string, for which we will see examples below:\n",
    "- **text.strip(char)** -> list: returns a list with the elements of string, split at char (or a space by default)\n",
    "- **text.find(string)**, **text.index(string)** -> int: returns the position (index) of the first occurrence of string\n",
    "- **text.count(string)** -> int: returns number of occurrences of string in text\n",
    "- **text.startswith(string)** -> boolean: returns True whether text starts with string\n",
    "- **text.strip()**: modifies text (not in place!) by eliminating leading and trailing whitespaces\n",
    "- **text.upper()**, **text.lower()**: modifies text (not in place!) by making all characters upper (lower) cases\n",
    "- **text{}.format(num)** -> str: inserts num in text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'list'>\n",
      "['Received:', 'from', 'Exchange03.ifo.local', '(192.168.0.103)', 'by', 'Exchange03.ifo.local']\n"
     ]
    }
   ],
   "source": [
    "line = text[0]\n",
    "\n",
    "line.split()\n",
    "print( type(line) )\n",
    "\n",
    "line = line.split()\n",
    "print( type(line) )\n",
    "print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that strings are immutable: methods do not work ``in place''.\n",
    "\n",
    "You can parse strings and check if they contain a certain substring by using the **find** and **index** methods. They return the position (index) of the *first* occurrence of the substring. Note that if the substring is not in the text, **find** will return -1 while **index** will throw an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text_all' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-abce1c0fc6c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Schmitt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpos\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpos\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpos\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpos\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapitalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'text_all' is not defined"
     ]
    }
   ],
   "source": [
    "pos = text_all.find('Schmitt')\n",
    "print(text_all[pos : pos + 7])\n",
    "print(text_all[pos : pos + 7].upper(), text_all[pos : pos + 7].lower())\n",
    "print(text_all[pos + 1 : pos + 7].capitalize())\n",
    "\n",
    "print(text_all.index('chmitt'))\n",
    "print(text_all.find('Chmitt'))\n",
    "# print(text_all.index('Chmitt')) -> throws an error!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are not interested in where a substring is contained in a string, but how often, use the **count** method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_all.count('ifo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterating over a file handle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In many cases, you may not be interested in the complete text, but only in certain parts of it or looking for specific information contained in the text. For example, assume you want to extract all email addresses in the text. One way to do this would be use the file handle as an iterator and store all lines that contain a '@' in a list: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['From: \"Huber, Matthias\" <Huber@ifo.de>\\n', 'To: \"Schmitt, Alex\" <Schmitt@ifo.de>\\n', 'Message-ID: <23211122c2f5403e81a78feb4d32a00e@ifo.de>\\n', 'X-MS-TNEF-Correlator: <23211122c2f5403e81a78feb4d32a00e@ifo.de>\\n', 'Return-Path: Huber@ifo.de\\n']\n"
     ]
    }
   ],
   "source": [
    "fh = open(fname)\n",
    "\n",
    "addresses = []\n",
    "for line in fh:\n",
    "    if line.find('@') > 0:\n",
    "        addresses.append(line)\n",
    "    \n",
    "print(addresses)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words, this reduces a potentially long text to those lines that may contain relevant information. Closer inspection of the resulting list shows that there are two email addresses in lines that start with 'From: ' and with 'To: '. We can use this information to parse the text again, this time making our query more precise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['From: \"Huber, Matthias\" <Huber@ifo.de>', 'To: \"Schmitt, Alex\" <Schmitt@ifo.de>']\n"
     ]
    }
   ],
   "source": [
    "fh = open(fname)\n",
    "\n",
    "addresses = []\n",
    "for line in fh:\n",
    "    if line.startswith('From') or line.startswith('To'):\n",
    "        addresses.append(line.strip())\n",
    "    \n",
    "print(addresses) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there are better ways to parse a text for specific characters, as we will see in a bit. \n",
    "\n",
    "Often it is not necessary to parse the whole text. For example, if you are only interested in the subject of an email, you can stop the loop after the relevant line, using a **break** statement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "github\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fh = open(fname)\n",
    "\n",
    "addresses = []\n",
    "for line in fh:\n",
    "    if line.startswith('Subject'):\n",
    "        print(line[9:])\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'str'>\n",
      "1637\n"
     ]
    }
   ],
   "source": [
    "fh = open(fname)\n",
    "\n",
    "text = []\n",
    "for line in fh:\n",
    "    text.append(line.strip())\n",
    "print(type(text))\n",
    "print(type(text_all))\n",
    "print(sum([len(line) for line in text]))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the number of characters here is less than above, since I have stripped line breaks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing to Text Files\n",
    "\n",
    "So far, we have focused on how to read data from text files. We can also use Python to write a new text files or to add to an existing text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular Expressions\n",
    "\n",
    "Regular Expressions (\"regex\") are an idea that exist in many programming language, not only in Python. In Python, we need to import the module **re** in order to use them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wikipedia defines Regular Expressions as \"a sequence of characters that define a search pattern\" in a string. They require a bit of getting used to, but are extremely useful in the context of parsing through a text or a web page.\n",
    "\n",
    "A frequently used function in the **re** package is **findall**. It takes a regular expression and parses through a text, returning a list of all the occurrence of the expression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "['ifo', 'ifo', 'ifo', 'ifo', 'ifo', 'ifo', 'ifo', 'ifo', 'ifo', 'ifo', 'ifo', 'ifo']\n"
     ]
    }
   ],
   "source": [
    "print( len(re.findall('ifo', text_all)) )\n",
    "print( re.findall('ifo', text_all) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this simple example, the regular expression is just a string, **'ifo'**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Huber@ifo.de', 'Schmitt@ifo.de', 'e@ifo.de', 'e@ifo.de', 'Huber@ifo.de']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('[A-Za-z.]+@[a-z.]+', text_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tue, 28 Mar 2017 11:45:05 +0200']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('Date: (.+)', text_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tue, 28 Mar 2017 11:45:05 +0200',\n",
       " 'Tue, 28',\n",
       " 'Tue, 28 Mar 2017 11:45:05 +0200',\n",
       " 'Tue, 28 Mar 2017 11:45:05 +0200']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('Tue.+', text_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['03.',\n",
       " '.',\n",
       " '192.168.0.103',\n",
       " '03.',\n",
       " '.',\n",
       " '192.168.0.103',\n",
       " '1',\n",
       " '2',\n",
       " '256',\n",
       " '384',\n",
       " '384',\n",
       " '15.1.544.27',\n",
       " '28',\n",
       " '2017',\n",
       " '11',\n",
       " '45',\n",
       " '05',\n",
       " '0200',\n",
       " '03.',\n",
       " '.',\n",
       " '192.168.0.103',\n",
       " '03.',\n",
       " '.',\n",
       " '192.168.0.103',\n",
       " '1',\n",
       " '2',\n",
       " '256',\n",
       " '384',\n",
       " '384',\n",
       " '15.1.544.27',\n",
       " '28',\n",
       " '2017',\n",
       " '11',\n",
       " '45',\n",
       " '05',\n",
       " '0200',\n",
       " '03.',\n",
       " '.',\n",
       " '80',\n",
       " '10',\n",
       " '8',\n",
       " '53',\n",
       " '646',\n",
       " '03.',\n",
       " '.',\n",
       " '80',\n",
       " '10',\n",
       " '8',\n",
       " '53',\n",
       " '646',\n",
       " '15',\n",
       " '15.01.0544.030',\n",
       " '28',\n",
       " '2017',\n",
       " '11',\n",
       " '45',\n",
       " '05',\n",
       " '0200',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " '5',\n",
       " '2',\n",
       " '4',\n",
       " '6',\n",
       " '1',\n",
       " '28',\n",
       " '2017',\n",
       " '11',\n",
       " '45',\n",
       " '05',\n",
       " '0200',\n",
       " '23211122',\n",
       " '2',\n",
       " '5403',\n",
       " '81',\n",
       " '78',\n",
       " '4',\n",
       " '32',\n",
       " '00',\n",
       " '.',\n",
       " '1',\n",
       " '23211122',\n",
       " '2',\n",
       " '5403',\n",
       " '81',\n",
       " '78',\n",
       " '4',\n",
       " '32',\n",
       " '00',\n",
       " '.',\n",
       " '1.0',\n",
       " '03.',\n",
       " '.',\n",
       " '04',\n",
       " '192.168.2.216',\n",
       " '78661',\n",
       " '8',\n",
       " '17',\n",
       " '409',\n",
       " '1497',\n",
       " '08',\n",
       " '475',\n",
       " '1',\n",
       " '23',\n",
       " '.',\n",
       " '1.0',\n",
       " '00',\n",
       " '00',\n",
       " '00.2656386']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('[0-9.]+', text_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Application: parsing a scientific text for numeric data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing the text with **readlines** works, but actually returns a list of paragraphs, rather than lines. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text consists of 16808 characters.\n"
     ]
    }
   ],
   "source": [
    "fname = 'jeem.txt'\n",
    "fh = open(fname)\n",
    "text = fh.readlines()\n",
    "\n",
    "print('The text consists of {} characters.'.format( sum([len(x) for x in text]) ) ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to obtain a list with lines rather than paragraphs, we can loop though the file handle and convert the object in each iteration -- a paragraph -- to a list of lines, using the **split** methods. We use '. ' (i.e. a stop with following space) as the argument at which to split. We can then add the contents of this list to a list called **text** which contains all the previous lines. Before this step, I clean the paragraph of leading and trailing white space using **strip**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'str'>\n",
      "16439\n"
     ]
    }
   ],
   "source": [
    "fh = open(fname)\n",
    "\n",
    "text = []\n",
    "for item in fh:\n",
    "    ## eliminate whitespace\n",
    "    paragraph = item.strip()\n",
    "    ## substitutions\n",
    "    paragraph = re.sub('et al.', 'et al', paragraph)\n",
    "    paragraph = re.sub('[0-9]+\\)', ')', paragraph)\n",
    "    paragraph = re.sub('[0-9]+;', ';', paragraph)\n",
    "    paragraph = re.sub('[0-9]+ ;', ';', paragraph)\n",
    "\n",
    "    text = text + paragraph.split('. ')\n",
    "print(type(text))\n",
    "print(type(text_all))\n",
    "print(sum([len(line) for line in text])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Introduction',\n",
       " 'The European Union Emissions Trading System (EU ETS) is currently the largest carbon trading system in the world, unless and until it is overtaken by the Chinese national carbon trading scheme planned for introduction in 2017 (Jotzo and Löschel, ;  Zhang et al, )',\n",
       " 'Although the EU ETS is meeting its core objective – EU emissions covered by the scheme remain below the total emissions cap – it is sometimes described as having ‘failed’ because prices are too low to incentivise substantial short-run emissions reductions and too volatile to provide adequate long-run incentives for investments in clean technologies.',\n",
       " '',\n",
       " 'European Allowances (EUAs) – the unit of compliance – have traded below €10 from 2013 onwards (EEX )',\n",
       " 'The price is below most estimates of the social cost of carbon for example as used in US government regulatory analysis (Greenstone et al, ; Goulder and Williams, ; United States Interagency Group, )',\n",
       " 'It is also low relative to the implicit price used internally by many companies when making their investment decisions',\n",
       " 'For instance, several multinational oil companies use internal screening prices of US $40/€35 or more (Kossoy et al, ), even though they operate in jurisdictions that are, on the whole, subject to lighter carbon regulation than in Europe.',\n",
       " '',\n",
       " 'There are various reasons for the low EUA prices']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The European Union Emissions Trading System (EU ETS) is currently the largest carbon trading system in the world, unless and until it is overtaken by the Chinese national carbon trading scheme planned for introduction in 2017 (Jotzo and Löschel, ;  Zhang et al, )\n",
      "European Allowances (EUAs) – the unit of compliance – have traded below €10 from 2013 onwards (EEX )\n",
      "For instance, several multinational oil companies use internal screening prices of US $40/€35 or more (Kossoy et al, ), even though they operate in jurisdictions that are, on the whole, subject to lighter carbon regulation than in Europe.\n",
      "Emissions allowances issued each year began to exceed actual annual emissions in 2009 (Redman and Convery, ) and a large surplus has been built up through banking\n",
      "The 2030 Climate and Energy Reform Package (European Council, ) decided that the annual (linear) reduction factor for the EU ETS will be increased from 1.74 to 2.2 percent per annum from 2021-2030\n",
      "In November 2012, the European Commission released a paper on the “The state of the European carbon market in 2012” and proposed several structural measures to reform the EU ETS (European Commission, ) outside of the usual review cycle\n",
      "The first policy proposal was to “backload” – postpone the issuance of – 900 million allowances from 2014-2016 auctions to 2019-2020 auctions\n",
      "This idea was put into legislation in early 2014, but it had limited impact on prices\n",
      "The MSR might be described as a quantity-based rule aimed at balancing supply and demand (European Union, ),1 operating as follows\n",
      "If the total number of allowances in circulation2 is\n",
      "less than 400 m, then the MSR releases 100 m allowances into circulation unless the MSR is empty;\n",
      "between 400 m and 833 m, then the market functions without intervention;\n",
      "greater than 833 m, then the MSR absorbs 12 per cent of allowances in circulation each year by deducting them from future auctions.\n",
      "One motivation for this was to avoid the MSR being perceived to be “primarily of a fiscal nature” under article 192 §2 of the Lisbon Treaty (European Union, ) requiring unanimity of EU members for adoption\n",
      "Led by the German Institute for Economic Research (DIW Berlin), an international research consortium was formed in 2014 to support the European Commission by considering the design options using different models and different methodological approaches – theoretical and experimental\n",
      "Consortium members were drawn from a dozen different institutions in the EU, USA, and Australia.3\n",
      "Given the timing of the European policy agenda – with the Climate and Energy package in October 2014 and final decisions on the MSR to be made in 2015 – papers were presented and discussed at a September 2014 Workshop at DIW Berlin, and at a special policy session at the European Association of Environmental and Resource Economics conference in Helsinki in June 2015\n",
      "The legal and political issues specific to the EU were among the main motivations for selecting this category of intervention, given the political constraints of reforming a scheme operating in 28 European countries.\n",
      "In the event, the recommendation of Neuhoff et al () appears to have been adopted and the first review is required in 2021.\n",
      "In summary, has the MSR given the EU ETS the shot in the arm as intended? As of 2016, it might seem not\n",
      "Longer-term expectations about evolving 2030 policy and the impact of a possible “Brexit” enhance regulatory risks\n",
      "However, the full impacts of the MSR may only be observed once it commences operation in 2019 and is filled with allowances, likely in the early 2020s\n"
     ]
    }
   ],
   "source": [
    "text_num = []\n",
    "for item in text:\n",
    "    if re.search('[0-9]+', item):\n",
    "        text_num.append(item)\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
